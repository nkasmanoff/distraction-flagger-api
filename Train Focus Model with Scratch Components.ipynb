{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vercel has a limit on the memory on the server. The bottleneck for me is sklearn. So to go around this, I'm creating from-scratch implementations of TFIDF and linear regression :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# can still use the evaluation stuff for now haha\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load the dataset\n",
    "df = pd.read_excel('Tabs Dataset.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "df['tab_name'] = df['url_and_tab_name'].apply(lambda x: x.split(' | ')[1])\n",
    "df['on_topic'].fillna(0, inplace=True)\n",
    "df['on_topic'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty imbalanced problem! I am not focusing much :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the from scratch implementation. I would not advice copilot or chatgpt here as it\n",
    "# defeats the point, and they are also not perfect!\n",
    "\n",
    "# Instead, follow tutorials like https://www.kaggle.com/code/yassinehamdaoui1/creating-tf-idf-model-from-scratch\n",
    "\n",
    "class TFIDF:\n",
    "    def __init__(self):\n",
    "        self.documents = None\n",
    "        self.vocab = None\n",
    "        self.idf = None\n",
    "        self.tf = None\n",
    "        self.tfidf = None\n",
    "\n",
    "    def fit(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vocab = list(set([word for doc in documents for word in doc.split()]))\n",
    "        self.idf = np.zeros(len(self.vocab))\n",
    "        self.tf = np.zeros((len(self.documents), len(self.vocab)))\n",
    "        self.tfidf = np.zeros((len(self.documents), len(self.vocab)))\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            for j, word in enumerate(self.vocab):\n",
    "                self.tf[i, j] = doc.split().count(word) / len(doc.split())\n",
    "                if self.tf[i, j] > 0:\n",
    "                    self.idf[j] += 1\n",
    "        self.idf = np.log(len(self.documents) / self.idf)\n",
    "        self.tfidf = self.tf * self.idf\n",
    "    \n",
    "    def transform(self, documents):\n",
    "        tfidf = np.zeros((len(documents), len(self.vocab)))\n",
    "        for i, doc in enumerate(documents):\n",
    "            for j, word in enumerate(self.vocab):\n",
    "                tfidf[i, j] = doc.split().count(word) / len(doc.split()) * self.idf[j]\n",
    "        return tfidf\n",
    "    \n",
    "    def fit_transform(self, documents):\n",
    "        self.fit(documents)\n",
    "        return self.tfidf\n",
    "    \n",
    "\n",
    "# test the data\n",
    "tfidf = TFIDF()\n",
    "tfidf.fit(df['tab_name'].values)\n",
    "X = tfidf.transform(df['tab_name'].values)\n",
    "\n",
    "\n",
    "y = df['on_topic'].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked, but as we can see, it leaves many more columns than data points in an already unbalanced dataset! \n",
    "\n",
    "To resolve, let's use L1 regularization on top of logistic regression.\n",
    "\n",
    "Alternatively, we can use feature engineering to further refine the word counting above to only include alphabetic characters, try different tokenizers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, n_iters=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # initialize weights and bias to zeros\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # gradient descent optimization\n",
    "        for i in range(self.n_iters):\n",
    "            # calculate predicted probabilities and cost\n",
    "            z = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self._sigmoid(z)\n",
    "            cost = (-1 / n_samples) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "            \n",
    "            # calculate gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))            \n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            # update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "    def predict(self, X,probabilities=False):\n",
    "        # calculate predicted probabilities\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self._sigmoid(z)\n",
    "        if probabilities:\n",
    "            return y_pred\n",
    "        \n",
    "        # convert probabilities to binary predictions\n",
    "        return np.round(y_pred).astype(int)\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "# initialize logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# train model on sample dataset\n",
    "lr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X,probabilities=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = .2\n",
    "predictions[predictions > thresh] = 1\n",
    "predictions[predictions <= thresh] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_and_tab_name</th>\n",
       "      <th>on_topic</th>\n",
       "      <th>tab_name</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://huggingface.co/docs/transformers/peft ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Load adapters with 🤗 PEFT</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://leetcode.com/problems/search-in-rotate...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LeetCode - The World's Leading Online Programm...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://uvadlc-notebooks.readthedocs.io/en/lat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Guide 2: Research projects with PyTorch — UvA ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://phare.health/ | Phare Health</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Phare Health</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/3732132352/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>https://chat.openai.com/ | Applying for Develo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Applying for Development Seed</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>https://www.climatechange.ai/ | Climate Change...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Climate Change AI</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>https://arxiv.org/pdf/2306.17271.pdf | Disaste...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DisasterResponseGPT: Large Language Models for...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>https://plotly.com/ | Plotly: Low-Code Data Ap...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Plotly: Low-Code Data App Development</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>https://www.digitalocean.com/community/tutoria...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>How To Make a Web Application Using Flask in P...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      url_and_tab_name  on_topic  \\\n",
       "1    https://huggingface.co/docs/transformers/peft ...       1.0   \n",
       "2    https://leetcode.com/problems/search-in-rotate...       1.0   \n",
       "3    https://uvadlc-notebooks.readthedocs.io/en/lat...       1.0   \n",
       "7                 https://phare.health/ | Phare Health       1.0   \n",
       "8    https://www.linkedin.com/jobs/view/3732132352/...       1.0   \n",
       "..                                                 ...       ...   \n",
       "316  https://chat.openai.com/ | Applying for Develo...       1.0   \n",
       "319  https://www.climatechange.ai/ | Climate Change...       1.0   \n",
       "334  https://arxiv.org/pdf/2306.17271.pdf | Disaste...       0.0   \n",
       "374  https://plotly.com/ | Plotly: Low-Code Data Ap...       1.0   \n",
       "391  https://www.digitalocean.com/community/tutoria...       0.0   \n",
       "\n",
       "                                              tab_name  predictions  \n",
       "1                            Load adapters with 🤗 PEFT          1.0  \n",
       "2    LeetCode - The World's Leading Online Programm...          1.0  \n",
       "3    Guide 2: Research projects with PyTorch — UvA ...          1.0  \n",
       "7                                         Phare Health          1.0  \n",
       "8                            Machine Learning Engineer          1.0  \n",
       "..                                                 ...          ...  \n",
       "316                      Applying for Development Seed          1.0  \n",
       "319                                  Climate Change AI          1.0  \n",
       "334  DisasterResponseGPT: Large Language Models for...          1.0  \n",
       "374              Plotly: Low-Code Data App Development          1.0  \n",
       "391  How To Make a Web Application Using Flask in P...          1.0  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['predictions'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should work in production! This was scratch, transferring this over to something nice now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
